{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49ef0670",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7d5fd",
   "metadata": {},
   "source": [
    "### Assumptions:-\n",
    "1. Normality: The data within each group should follow a roughly normal distribution. This means that the data points should be symmetrically distributed around the mean. Violations of this assumption can lead to skewed or non-normal distributions, which can impact the validity of ANOVA. For example, if we have count data that is highly skewed, it may not meet the normality assumption.\n",
    "2. Absence of oulier.\n",
    "3. Homogeneity of Variance: The variance of the data in each group should be roughly equal. In other words, the spread of data points around the mean should be similar across all groups. If one group has a much larger variance than others, it can lead to unequal variances and affect the validity of ANOVA.\n",
    "4. Samples are independent : The observations in each group must be independent of each other. This means that the value of one observation should not be influenced by or related to the value of any other observation in the same group.\n",
    "\n",
    "### Examples of violations that could impact the validity of ANOVA results:\n",
    "\n",
    "1. Non-normality: If the data within one or more groups significantly deviates from a normal distribution, ANOVA results may be unreliable. For example, in a study measuring exam scores, if the scores in one group are heavily skewed and not normally distributed, ANOVA results may be affected.\n",
    "\n",
    "2. Unequal Variances: If the variances in different groups are significantly different, ANOVA may not be appropriate. For instance, in a manufacturing process study comparing the quality of products produced by different machines, if one machine consistently produces parts with much higher variation than others, ANOVA assumptions may be violated.\n",
    "\n",
    "3. Non-independence: If the observations within groups are not independent, such as in a repeated-measures design where the same subjects are measured under different conditions, ANOVA may not be suitable. In this case, a repeated measures ANOVA or a mixed-effects model might be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da378118",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067de8f4",
   "metadata": {},
   "source": [
    "### Types:\n",
    "1. One-Way ANOVA: One-way ANOVA is used when we have one categorical independent variable (with three or more levels or groups) and one continuous dependent variable. It is uesd to determine whether there are statistically significant differences in the means of the dependent variable across the various groups.\n",
    "\n",
    "2. Repeated Measures ANOVA : It is used when we have one categorical independent variable and one continuous dependent variable, but the same subjects are measured under multiple conditions or time points. It is employed to analyze changes within subjects across different conditions or time periods.\n",
    "\n",
    "3. Factorial ANOVA: It is used when we have two or more categorical independent variables (factors) and one continuous dependent variable. It is employed to examine the main effects of each factor and any interaction effects between the factors on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bcb00a",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d3ec7",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the division of the total variation in a dataset into different sources of variation, which are then used to calculate the F-statistic and test for significant differences between groups. In ANOVA, the total variance is partitioned into two components: the variance between groups and the variance within groups.\n",
    "\n",
    "The variance between groups represents the differences between the group means, and is calculated by taking the sum of squares between groups (SSB). The variance within groups represents the variability within each group, and is calculated by taking the sum of squares within groups (SSW). The total variance is calculated by taking the sum of squares total (SST), which is the sum of the squared differences between each data point and the overall mean.\n",
    "\n",
    "By understanding the partitioning of variance in ANOVA, we can determine the proportion of the total variance that can be attributed to the differences between groups (SSB), and the proportion that is due to random error within each group (SSW). This allows us to test whether the differences between groups are statistically significant, and to determine the magnitude of these differences relative to the overall variability in the dataset. It also allows us to identify the sources of variation that are most important in explaining the differences between groups, and to assess the validity of our conclusions based on the assumptions underlying the ANOVA model.\n",
    "\n",
    "In summary, understanding the partitioning of variance in ANOVA is important for interpreting the results of the analysis, identifying sources of variation that contribute to group differences, and evaluating the assumptions underlying the ANOVA model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63edc1ad",
   "metadata": {},
   "source": [
    "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2061c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 946.9333333333335\n",
      "Explained Sum of Squares (SSE): 836.9333333333332\n",
      "Residual Sum of Squares (SSR): 110.00000000000034\n",
      "F-statistic: 45.65090909090895\n",
      "P-value: 2.457195342753238e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for each group (replace with your data)\n",
    "group1 = np.array([10, 12, 15, 14, 18])\n",
    "group2 = np.array([22, 25, 28, 30, 32])\n",
    "group3 = np.array([8, 9, 12, 10, 11])\n",
    "\n",
    "# Combine all data into a single array\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the overall mean (Grand Mean)\n",
    "grand_mean = np.mean(all_data)\n",
    "\n",
    "# Calculate Total Sum of Squares (SST)\n",
    "sst = np.sum((all_data - grand_mean) ** 2)\n",
    "\n",
    "# Calculate the group means\n",
    "mean_group1 = np.mean(group1)\n",
    "mean_group2 = np.mean(group2)\n",
    "mean_group3 = np.mean(group3)\n",
    "\n",
    "# Calculate Explained Sum of Squares (SSE)\n",
    "sse = len(group1) * (mean_group1 - grand_mean) ** 2 + len(group2) * (mean_group2 - grand_mean) ** 2 + len(group3) * (mean_group3 - grand_mean) ** 2\n",
    "\n",
    "# Calculate Residual Sum of Squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "# Degrees of Freedom\n",
    "df_between = 2  # Number of groups minus 1\n",
    "df_within = len(all_data) - 3  # Total number of observations minus the number of groups\n",
    "\n",
    "# Mean Squares\n",
    "ms_between = sse / df_between\n",
    "ms_within = ssr / df_within\n",
    "\n",
    "# F-statistic\n",
    "f_statistic = ms_between / ms_within\n",
    "\n",
    "# P-value\n",
    "p_value = 1 - stats.f.cdf(f_statistic, df_between, df_within)\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac6ad26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 12, 15, 14, 18, 22, 25, 28, 30, 32,  8,  9, 12, 10, 11])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a1a8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.06666667, -5.06666667, -2.06666667, -3.06666667,  0.93333333,\n",
       "        4.93333333,  7.93333333, 10.93333333, 12.93333333, 14.93333333,\n",
       "       -9.06666667, -8.06666667, -5.06666667, -7.06666667, -6.06666667])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=(all_data - grand_mean)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90786894",
   "metadata": {},
   "source": [
    "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a0bc98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d458bdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor A: 8.012820512818848\n",
      "Main Effect of Factor B: 0.17948717948715617\n",
      "Interaction Effect: 14.820512820512734\n"
     ]
    }
   ],
   "source": [
    "# Create a sample dataset (replace with your data)\n",
    "data = pd.DataFrame({\n",
    "    'FactorA': [2,4,2,8,8,4],\n",
    "    'FactorB': [7,9,7,9,7,9],\n",
    "    'Y': [10, 12, 15, 14, 18, 20]\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Y ~ FactorA * FactorB', data=data).fit()\n",
    "\n",
    "# Perform the two-way ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the main effects and interaction effect\n",
    "main_effect_A = anova_table['sum_sq']['FactorA']\n",
    "main_effect_B = anova_table['sum_sq']['FactorB']\n",
    "interaction_effect = anova_table['sum_sq']['FactorA:FactorB']\n",
    "\n",
    "# Print the results\n",
    "print(\"Main Effect of Factor A:\", main_effect_A)\n",
    "print(\"Main Effect of Factor B:\", main_effect_B)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39db6b1",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36887d5",
   "metadata": {},
   "source": [
    "Assume significant value is 0.05\n",
    "\n",
    "**Null Hypothesis (H0):** The null hypothesis in a one-way ANOVA states that there are no significant differences among the group means. In other words, all group means are equal.\n",
    "\n",
    "**Alternative Hypothesis (Ha):** The alternative hypothesis in a one-way ANOVA states that at least one group mean is significantly different from the others.\n",
    "\n",
    "**F-Statistic (5.23):** The F-statistic is a measure of the ratio of the variance between groups to the variance within groups. A larger F-statistic suggests that there may be more substantial differences between group means.\n",
    "\n",
    "**p-value (0.02):** The p-value is the probability of observing an F-statistic as extreme as, or more extreme than, the one calculated from our data, assuming that the null hypothesis is true. In other words, it tells us how likely it is to obtain such a result purely by chance.\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "Since the p-value (0.02) is less than the commonly chosen significance level (e.g., 0.05), you would typically reject the null hypothesis (H0) in favor of the alternative hypothesis (Ha). This means that we have evidence to conclude that there are significant differences among the group means.\n",
    "\n",
    "In summary, based on the F-statistic and p-value, we can conclude that there are significant differences between the groups in our study, but further analysis may be needed to determine exactly which groups differ from one another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c694ec2",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741dbfff",
   "metadata": {},
   "source": [
    "### common methods for handling missing data in repeated measures ANOVA :\n",
    "\n",
    "1. Listwise Deletion:\n",
    "This approach involves removing any cases (subjects or observations) with missing data across all time points or conditions. In other words, we only analyze subjects who have complete data for all measurements.\n",
    "2. Pairwise Deletion :\n",
    "This approach analyzes all subjects with available data for each specific comparison within the repeated measures design. In essence, it uses all available data for each pair of time points or conditions.\n",
    "3. Mean Imputation:\n",
    "Missing values are replaced with the mean of the available data for the respective time point or condition.\n",
    "4. Last Observation Carried Forward (LOCF):\n",
    "This method involves using the last observed value of a variable as a substitute for any missing values for that variable at later time points. LOCF can produce biased estimates if the assumption that missing values are missing completely at random (MCAR) is not met.\n",
    "\n",
    "### Consequences:-\n",
    "### Positive Consequences:\n",
    "\n",
    "Preservation of Data: Imputation methods allow us to retain more data and use available information to fill in missing values. This can maximize the use of your dataset.\n",
    "\n",
    "Improved Statistical Power: By preserving sample size and reducing random variability introduced by missing data, imputation methods can enhance the statistical power of your analysis, making it easier to detect true effects or relationships.\n",
    "\n",
    "Reduced Bias: When missing data are not missing completely at random (MCAR) but are missing at random (MAR), proper imputation methods can help reduce bias in parameter estimates, leading to more accurate conclusions.\n",
    "\n",
    "More Reliable Inferences: Using appropriate imputation methods can result in more reliable statistical inferences, such as hypothesis testing and confidence interval estimation, compared to ad hoc methods like listwise deletion or mean imputation.\n",
    "\n",
    "### Negative Consequences:\n",
    "\n",
    "Introduction of Bias: In some cases, imputation methods can introduce bias if the missing data mechanism is not properly accounted for or if the assumptions about the data are violated.\n",
    "\n",
    "Increased Complexity: Advanced imputation methods, like multiple imputation, can be computationally intensive and may require specialized software or statistical expertise. This complexity can be a drawback for some researchers.\n",
    "\n",
    "Assumption Sensitivity: The effectiveness of imputation methods depends on the correctness of assumptions about the missing data mechanism. Using the wrong assumptions can lead to incorrect conclusions.\n",
    "\n",
    "Loss of Information: While imputation methods can preserve more data, they may not fully capture the true variability in the missing data. This can result in underestimation of standard errors and inflated significance levels.\n",
    "\n",
    "Misleading Results: Using imputation methods without appropriate sensitivity analyses or without considering the potential impact of missing data on study findings can lead to misleading or incorrect conclusions.\n",
    "\n",
    "Complexity in Reporting: Properly reporting the methods used for handling missing data, especially when using advanced techniques, can add complexity to research reports and may require more extensive documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77b0e5",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb70f17",
   "metadata": {},
   "source": [
    "### common post-hoc tests used after ANOVA:-\n",
    "1. Tukey's Honestly Significant Difference (Tukey's HSD):\n",
    "\n",
    "When to Use: Tukey's HSD is used when we have conducted a one-way ANOVA and found a significant overall difference among three or more groups. It is appropriate when we want to test all possible pairwise group comparisons while controlling the familywise error rate.\n",
    "\n",
    "Example: Suppose we conducted an experiment to compare the performance of four different training methods (A, B, C, and D) on a task, and the ANOVA showed a significant overall difference. Tukey's HSD would help determine which specific pairs of training methods have significantly different effects on task performance.\n",
    "\n",
    "2. Bonferroni Correction:\n",
    "\n",
    "When to Use: The Bonferroni correction can be applied to control the familywise error rate when conducting multiple pairwise comparisons after ANOVA. It's a conservative method that reduces the risk of Type I errors (false positives).\n",
    "\n",
    "Example: If we have conducted multiple pairwise comparisons between groups, such as comparing the effects of different treatments on a medical condition, we may use the Bonferroni correction to adjust the significance level for each comparison to maintain an overall desired level of significance.\n",
    "\n",
    "3. Duncan's Multiple Range Test:\n",
    "\n",
    "When to Use: Duncan's test is suitable when we want to compare all possible pairwise group means, but it tends to be less conservative than Tukey's HSD. It is used when we have conducted a one-way ANOVA and found a significant overall difference.\n",
    "\n",
    "Example: In an agricultural study, we are comparing the yields of several varieties of a crop. After ANOVA indicates a significant difference, we can use Duncan's test to determine which pairs of varieties have significantly different yields.\n",
    "\n",
    "4. Scheffé's Test:\n",
    "\n",
    "When to Use: Scheffé's test is a robust post-hoc test that can be used when we have conducted a one-way ANOVA with unequal sample sizes or unequal variances. It provides a conservative control of the familywise error rate.\n",
    "\n",
    "Example: In a psychology study, we compare the effectiveness of three different therapies on anxiety reduction. Scheffé's test can be used to determine if any of the therapies are significantly better or worse than the others while considering the unequal sample sizes in each therapy group.\n",
    "\n",
    "5. Holm-Bonferroni Method:\n",
    "\n",
    "When to Use: The Holm-Bonferroni method is a correction method used to control the familywise error rate when conducting multiple pairwise comparisons. It is less conservative than the Bonferroni correction.\n",
    "\n",
    "Example: In a marketing research study, we compare the sales performance of several product variants across different regions. After ANOVA reveals a significant difference, we can apply the Holm-Bonferroni method to assess which specific pairs of product variants exhibit significant differences in sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930e79ff",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "392f2876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ece2da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 3.9399777137666927\n",
      "p-value: 0.02153653359944104\n",
      "We reject the null hypothesis.\n",
      "Conclusion : The mean weight loss is different for at least one diet.\n"
     ]
    }
   ],
   "source": [
    "# Generate simulated data assuming normal distribution with same variance\n",
    "np.random.seed(1)\n",
    "\n",
    "diet_A = np.random.normal(3, 2, 50)\n",
    "diet_B = np.random.normal(2, 1, 50)\n",
    "diet_C = np.random.normal(2.5, 1.5, 50)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "null_hypothesis = \"The mean weight loss is the same for all three diets.\"\n",
    "alternate_hypothesis = \"The mean weight loss is different for at least one diet.\"\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"We reject the null hypothesis.\")\n",
    "    print(f\"Conclusion : {alternate_hypothesis}\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis.\")\n",
    "    print(f\"Conclusion : {null_hypothesis}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae15c94",
   "metadata": {},
   "source": [
    "# Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0efe5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82ff8fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        sum_sq    df         F    PR(>F)\n",
      "Software             11.141545   2.0  2.113814  0.142706\n",
      "Experience            2.102143   1.0  0.797652  0.380665\n",
      "Software:Experience   6.013261   2.0  1.140857  0.336272\n",
      "Residual             63.249921  24.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Generate random data (replace with your actual data)\n",
    "np.random.seed(0)\n",
    "n = 30\n",
    "software_programs = np.random.choice(['A', 'B', 'C'], n)\n",
    "experience_level = np.random.choice(['Novice', 'Experienced'], n)\n",
    "completion_time = np.random.normal(loc=10, scale=2, size=n)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Software': software_programs,\n",
    "                     'Experience': experience_level,\n",
    "                     'Time': completion_time})\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "model = ols('Time ~ Software * Experience', data=data).fit()\n",
    "\n",
    "# Perform the two-way ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Interpret the results\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425a525",
   "metadata": {},
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2531b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab8cf092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test Results:\n",
      "t-statistic: -1.6677351961320235\n",
      "p-value: 0.09856078338184605\n",
      "Interpretation: There is no significant difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "# Generate random data (replace with your actual data)\n",
    "np.random.seed(0)\n",
    "n_control = 50\n",
    "n_experimental = 50\n",
    "\n",
    "control_group = np.random.normal(loc=75, scale=10, size=n_control)\n",
    "experimental_group = np.random.normal(loc=80, scale=10, size=n_experimental)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Group': ['Control'] * n_control + ['Experimental'] * n_experimental,\n",
    "                     'Test_Score': np.concatenate([control_group, experimental_group])})\n",
    "\n",
    "# Conduct a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Interpret the t-test results\n",
    "if p_value < 0.05:\n",
    "    interpretation = \"There is a significant difference in test scores between the control and experimental groups.\"\n",
    "else:\n",
    "    interpretation = \"There is no significant difference in test scores between the control and experimental groups.\"\n",
    "\n",
    "print(\"Two-Sample T-Test Results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"Interpretation:\", interpretation)\n",
    "\n",
    "# Perform a post-hoc test (Tukey's HSD) if the results are significant\n",
    "if p_value < 0.05:\n",
    "    posthoc = pairwise_tukeyhsd(data['Test_Score'], data['Group'], alpha=0.05)\n",
    "    print(\"\\nPost-Hoc Tukey's HSD Results:\")\n",
    "    print(posthoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90942d88",
   "metadata": {},
   "source": [
    "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "111814c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf739cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Way ANOVA Results:\n",
      "F-statistic: 54.894093901757174\n",
      "p-value: 3.803030787231263e-16\n",
      "Interpretation: There is no significant difference in test scores between the control and experimental groups.\n",
      "\n",
      "Post-Hoc Tukey's HSD Results:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      "group1 group2  meandiff p-adj   lower     upper   reject\n",
      "--------------------------------------------------------\n",
      "     A      B   60.4859 0.001   28.8477   92.1241   True\n",
      "     A      C  -78.1603 0.001 -109.7985  -46.5221   True\n",
      "     B      C -138.6461 0.001 -170.2843 -107.0079   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate random data (replace with your actual sales data)\n",
    "np.random.seed(0)\n",
    "n_days = 30\n",
    "sales_store_A = np.random.normal(loc=1000, scale=50, size=n_days)\n",
    "sales_store_B = np.random.normal(loc=1100, scale=60, size=n_days)\n",
    "sales_store_C = np.random.normal(loc=950, scale=45, size=n_days)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Store': ['A'] * n_days + ['B'] * n_days + ['C'] * n_days,\n",
    "                     'Sales': np.concatenate([sales_store_A, sales_store_B, sales_store_C])})\n",
    "\n",
    "# Perform a one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(sales_store_A, sales_store_B, sales_store_C)\n",
    "\n",
    "print(\"One-Way ANOVA Results:\")\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"Interpretation:\", interpretation)\n",
    "\n",
    "# Interpret the one-way ANOVA results\n",
    "if p_value < 0.05:\n",
    "    interpretation = \"There is a significant difference in daily sales between the three stores.\"\n",
    "else:\n",
    "    interpretation = \"There is no significant difference in daily sales between the three stores.\"\n",
    "\n",
    "\n",
    "# Perform a post-hoc test (Tukey's HSD) if the results are significant\n",
    "if p_value < 0.05:\n",
    "    posthoc = pairwise_tukeyhsd(data['Sales'], data['Store'], alpha=0.05)\n",
    "    print(\"\\nPost-Hoc Tukey's HSD Results:\")\n",
    "    print(posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ada50a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
